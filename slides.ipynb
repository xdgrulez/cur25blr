{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafi: Kafka Superpowers for Your Jupyter Notebook and Python\n",
    "<img src=\"pix/kafka.jpg\" style=\"width: 30%; height: 30%\"/>\n",
    "<img src=\"pix/jupyter.jpg\" style=\"width: 30%; height: 30%\"/>\n",
    "\n",
    "### Ralph Debusmann\n",
    "##### `ralph.debusmann@mgb.ch`\n",
    "\n",
    "<img src=\"pix/migros.png\" style=\"width: 20%; height: 20%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "* Part I: The Birth of Kafi\n",
    "\n",
    "* Part II: Three Paradigms for Using Kafi\n",
    "  * Shell/Python interpreter\n",
    "  * Juypter Notebooks\n",
    "  * Code (Microservices, FaaS, Agents...)\n",
    "\n",
    "* Part III: Use Cases for Kafi\n",
    "  * Kafka Administration\n",
    "  * Schema Registry Administration\n",
    "  * Kafka Backups incl. Kafka Emulation\n",
    "  * Simple Stream Processing\n",
    "  * Building a Bridge from Kafka to Pandas Dataframes and Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: The Birth of Kafi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pix/birth.jpg\" style=\"width: 35%; height: 35%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you would just like to create a topic on Kafka, list topics, produce some messages, or consume some messages, or search for messages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is often:\n",
    "* kafkacat/kcat\n",
    "* standard Kafka commandline tools (kafka-console-producer, kafka-console-consumer...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works...for a long time indeed. But how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still the State-of-the-Art Developer Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kcat -b localhost:9092 -L\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-topics --bootstrap-server localhost:9092 --list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not possible with kcat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-topics --bootstrap-server localhost:9092 --topic topic_json --create\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kcat -b localhost:9092 -t topic_json -P -K ,\n",
    "\n",
    "123,{\"bla\":123}\n",
    "456,{\"bla\":456}\n",
    "789,{\"bla\":789}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-console-producer --bootstrap-server localhost:9092 --topic topic_json --property parse.key=true --property key.separator=','\n",
    "\n",
    "123,{\"bla\":123}\n",
    "456,{\"bla\":456}\n",
    "789,{\"bla\":789}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Messages Using a Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(not even possible with kcat...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-avro-console-producer --bootstrap-server localhost:9092 --topic topic_avro --property schema.registry.url=http://localhost:8081 --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer --property value.schema='{\"type\":\"record\",\"name\":\"myrecord\",\"fields\":[{\"name\":\"bla\",\"type\":\"int\"}]}' --property parse.key=true --property key.separator=','\n",
    "\n",
    "123,{\"bla\": 123}\n",
    "456,{\"bla\": 456}\n",
    "789,{\"bla\": 789}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kcat -b localhost:9092 -t topic_json -C -o beginning\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-console-consumer --bootstrap-server localhost:9092 --topic topic_json --property print.key=true --from-beginning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kcat -b localhost:9092 -t topic_json -C -o beginning -e | grep 456\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "kafka-console-consumer --bootstrap-server localhost:9092 --topic topic_json --from-beginning | grep 456\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can't We Do Better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developed Kafi because I was frustrated with kcat and the standard Kafka commandline tools. Not by another commandline tool, but by building a Python module (=library).\n",
    "\n",
    "Regardless of whether you use Kafi in your shell or in a Jupyter notebook, you have a similar experience. And your life gets so much better. I promise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you can list topics, create topics, produce messages, consume messages or search for messages with Kafi.\n",
    "\n",
    "Because Kafi is a Python module, you first need to import it. Then, you create a Cluster object `c` reading from a configuration file:\n",
    "\n",
    "```\n",
    "from kafi.kafi import *\n",
    "c = Cluster(\"local\")\n",
    "```\n",
    "\n",
    "Then..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "c.ls()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "c.touch(\"topic_json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pr = c.producer(\"topic_json\")\n",
    "pr.produce({\"bla\": 123}, key=\"123\")\n",
    "pr.produce({\"bla\": 456}, key=\"456\")\n",
    "pr.produce({\"bla\": 789}, key=\"789\")\n",
    "pr.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce Messages Using a Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "t = \"topic_avro\"\n",
    "s = '{\"type\":\"record\",\"name\":\"myrecord\",\"fields\":[{\"name\":\"bla\",\"type\":\"int\"}]}'\n",
    "\n",
    "p = c.producer(t, value_type=\"avro\", value_schema=s)\n",
    "p.produce({\"bla\": 123}, key=\"123\")\n",
    "p.produce({\"bla\": 456}, key=\"456\")\n",
    "p.produce({\"bla\": 789}, key=\"789\")\n",
    "p.close()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "c.cat(\"topic_json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Three Paradigms for Using Kafi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pix/paradigms.jpg\" style=\"width: 35%; height: 35%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait, this talk is titled \"Kafka Superpowers for Your Jupyter Notebook and Python\". So where is the Jupyter notebook. Ok, here, but that's not what you probably ask yourselves...\n",
    "\n",
    "There are three main paradigms for using Kafi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell/Python Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first is in your shell using the Python interpreter, like we did in Part I above. That gives you a user/developer experience similar to bash/zsh + kcat or the standard Kafka commandline tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code (Microservices, FaaS, Agents...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Kafi is just a Python module, it is also super useful to use in your Python code. Either for smaller scripts, or even for building microservices, FaaS-functions, or agents (put in a pinch of llamaindex agents for example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally to them. You will see soon in Part III that Jupyter notebooks are a very convenient and powerful paradigm of using Kafi, especially for Python/Jupyter afficionados like Data Scientists etc.\n",
    "\n",
    "But... using Kafi in a Jupyter notebook is actually also very convenient and powerful for Kafka administrators or developers! You'll see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Use Cases for Kafi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pix/use_cases.jpg\" style=\"width: 35%; height: 35%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Registry Administration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Stream Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Backups incl. Kafka Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Bridge from Kafka to Pandas Dataframes and Files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
